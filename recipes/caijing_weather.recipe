#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import json
from calibre.web.feeds.news import BasicNewsRecipe

# —— 兼容 AbortRecipe —— 
try:
    from calibre.web.feeds.news import AbortRecipe
except ImportError:
    AbortRecipe = None

# —— 计算 BASE 目录 —— 
try:
    BASE = os.path.abspath(os.path.dirname(__file__))
except NameError:
    BASE = os.getcwd()
STATE_DIR  = os.path.join(BASE, 'state')
STATE_FILE = os.path.join(STATE_DIR, 'seen.json')
os.makedirs(STATE_DIR, exist_ok=True)


class CaijingWeather(BasicNewsRecipe):
    # —— 元信息 —— 
    title                  = '财经·天气（日增量）'
    oldest_article         = 6
    max_articles_per_feed  = 10000
    ignore_failed_feeds    = True
    tries, sleep           = 3, 2
    auto_cleanup, timeout  = True, 60
    no_stylesheets         = True

    # —— 确保实例总有这两个属性 —— 
    seen                   = set()
    new_cnt                = 0

# 去重整理后的RSS源链接和名称

feeds = [
    ('36氪 • 24h 热榜', 'https://rss.mifaw.com/articles/5c8bb11a3c41f61efd36683e/5c91d2e23882afa09dff4901'),
    ('工信部 • 文件公示', 'https://rsshub.app/gov/miit/wjgs'),
    ('雪球 • 今日话题', 'http://xueqiu.com/hots/topic/rss'),
    ('知乎收藏', 'https://r.hhbboo.com/users/1/web_requests/497/zhihu-mgwft-dt-eifh2oduyf3i23ek.xml'),
    ('第一财经周刊', 'http://feedmaker.kindle4rss.com/feeds/CBNweekly2008.weixin.xml'),
    ('三联生活周刊', 'http://feedmaker.kindle4rss.com/feeds/lifeweek.weixin.xml'),
    ('单读', 'http://feedmaker.kindle4rss.com/feeds/dandureading.weixin.xml'),
    ('华尔街见闻', 'http://feedmaker.kindle4rss.com/feeds/wallstreetcn.weixin.xml'),
    ('每日经济新闻', 'http://feedmaker.kindle4rss.com/feeds/nbdnews.weixin.xml'),
    ('warfalcon', 'http://feedmaker.kindle4rss.com/feeds/read01.weixin.xml'),
    ('地球知识局', 'http://feedmaker.kindle4rss.com/feeds/diqiuzhishiju.weixin.xml'),
    ('刘润', 'http://feedmaker.kindle4rss.com/feeds/runliu-pub.weixin.xml'),
    ('新世相', 'http://feedmaker.kindle4rss.com/feeds/thefair2.weixin.xml'),
    ('历史研习社', 'http://feedmaker.kindle4rss.com/feeds/mingqinghistory.weixin.xml'),
    ('新京报书评周刊', 'http://feedmaker.kindle4rss.com/feeds/ibookreview.weixin.xml'),
    ('半月谈', 'http://feedmaker.kindle4rss.com/feeds/banyuetan-weixin.weixin.xml'),
    ('环球科学', 'http://feedmaker.kindle4rss.com/feeds/ScientificAmerican.weixin.xml'),
    ('澎湃新闻', 'http://feedmaker.kindle4rss.com/feeds/thepapernews.weixin.xml'),
    ('小道消息', 'http://feedmaker.kindle4rss.com/feeds/WebNotes.weixin.xml'),
    ('虎嗅网', 'http://feedmaker.kindle4rss.com/feeds/huxiu_com.weixin.xml'),
    ('经济观察网', 'http://feedmaker.kindle4rss.com/feeds/eeo.xml'),
    ('中金在线', 'http://feedmaker.kindle4rss.com/feeds/cnfol-com.weixin.xml'),
    ('豆瓣: 经典短篇阅读', 'http://feedmaker.kindle4rss.com/feeds/group_classicreading.douban.xml'),
    ('FT中文网:今日焦点', 'http://feedmaker.kindle4rss.com/feeds/news.ftchinese.com.xml'),
    ('FT中文网:十大热门文章', 'http://feedmaker.kindle4rss.com/feeds/hotstoryby7day.ftchinese.com.xml'),
    ('BBC 中国', 'http://feedmaker.kindle4rss.com/feeds/cn-bbc.xml'),
    ('南方周末', 'http://feedmaker.kindle4rss.com/feeds/hot.infzm.com.xml'),
    ('丁香医生', 'http://feedmaker.kindle4rss.com/feeds/DingXiangYiSheng.weixin.xml'),
    ('知乎日报', 'http://feedmaker.kindle4rss.com/feeds/zhihu-daily.xml'),
    ('中国政府网 - 最新政策', 'https://rsshub.app/gov/zhengce/zuixin'),
    ('新闻 | 半岛电视台今日最新资讯', 'https://rsshub.app/aljazeera/chinese/news'),
    ('数据发布 - 国家统计局', 'https://rsshub.app/gov/stats/sj/zxfb'),
    ('人民网-时政', 'http://www.people.com.cn/rss/politics.xml'),
    ('China Research Center', 'http://www.chinacenter.net/feed/'),
    ('忽左忽右', 'https://justpodmedia.com/rss/left-right.xml'),
    ('上海书评', 'https://feedx.pw/rss/shanghaishuping.xml'),
    ('人物', 'http://feedmaker.kindle4rss.com/feeds/renwumag1980.weixin.xml'),
    ('果壳网', 'http://feedmaker.kindle4rss.com/feeds/Guokr42.weixin.xml'),
]

# 使用有序字典去重（保持顺序）
from collections import OrderedDict
feeds_cleaned = list(OrderedDict((link, name) for name, link in feeds_raw).items())

# 转换回目标格式
feeds_formatted = [(name, link) for link, name in feeds_cleaned]

import pandas as pd
import ace_tools as tools; tools.display_dataframe_to_user(name="去重整理后的RSS源", dataframe=pd.DataFrame(feeds_formatted, columns=["名称", "链接"]))


    def get_feeds(self):
        # Calibre ≥7 会清空 self.feeds，重载以返回类属性
        return list(self.__class__.feeds)

    def initialize(self):
        super().initialize()
        try:
            with open(STATE_FILE, 'r', encoding='utf-8') as f:
                self.seen = set(json.load(f))
        except Exception:
            self.seen = set()
        self.new_cnt = 0
        self.log(f'Init OK, seen {len(self.seen)} items; cwd={os.getcwd()}')

    def skip_article(self, a):
        # —— 调试：打印前 10 个 gid —— 
        if not hasattr(self, '_dbg_cnt'):
            self._dbg_cnt = 0
        if self._dbg_cnt < 10:
            self.log(f"DBG GID[{self._dbg_cnt}] title='{a.get('title')[:30]}' "
                     f"link={a.get('link')}")
            self._dbg_cnt += 1

        # —— 拼唯一键：URL + 发布日期 —— 
        date = a.get('published') or a.get('updated') or a.get('pubDate') or ''
        url  = a.get('link') or a.get('id') or a.get('guid') or ''
        gid  = f"{url}||{date}" if date else f"{url}||{a.get('title')}"

        if gid in self.seen:
            return True
        self.seen.add(gid)
        self.new_cnt += 1
        return False

    def get_browser(self):
        br = super().get_browser()
        br.set_proxies({})
        br.addheaders += [
            ('User-Agent',
             'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
             'Chrome/124 Safari/537.36'),
            ('Accept-Encoding', 'identity'),
        ]
        return br

    def postprocess_book(self, oeb, opts, log):
        # 统计真正进入 spine 的条目（封面+导读页之外）
        content_items = [i for i in oeb.spine if i.id not in ('cover', 'masthead')]
        real_cnt = len(content_items)
        log.info(f"★ DEBUG: new_cnt={getattr(self, 'new_cnt', 0)}, real_cnt={real_cnt}")
    
        # 判断是否应当生成电子书（Calibre 7推荐 real_cnt, Calibre 6可兼容new_cnt）
        if real_cnt == 0:
            log.info("★ DEBUG: No new articles in this run, aborting recipe gracefully.")
            if AbortRecipe:
                raise AbortRecipe('No new articles')
            else:
                self.abort_recipe_processing('No new articles')
            # 即使没有新文章也尝试写空 seen.json
            try:
                with open(STATE_FILE, 'w', encoding='utf-8') as f:
                    json.dump(list(self.seen), f)
                log.info(f"★ DEBUG: Wrote {len(self.seen)} gids to {STATE_FILE} (empty, after abort)")
            except Exception as e:
                log.info(f"★ DEBUG: Failed to write seen.json after abort: {e}")
            return
    
        # 有文章，正常写入 seen.json
        try:
            with open(STATE_FILE, 'w', encoding='utf-8') as f:
                json.dump(list(self.seen), f)
            log.info(f"★ DEBUG: Wrote {len(self.seen)} gids to {STATE_FILE}")
        except Exception as e:
            log.info(f"★ DEBUG: Failed to write seen.json: {e}")
